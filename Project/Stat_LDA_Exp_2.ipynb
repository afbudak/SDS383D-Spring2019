{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 4258)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lda\n",
    "import lda.datasets\n",
    "\n",
    "X = lda.datasets.load_reuters()\n",
    "matrix = X\n",
    "vocabulary = lda.datasets.load_reuters_vocab()\n",
    "titles = lda.datasets.load_reuters_titles()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dirichlet priors\n",
    "alpha      = 1\n",
    "beta       = 1\n",
    "\n",
    "\n",
    "#set the numbers\n",
    "n_docs = X.shape[0]\n",
    "n_topics = 20\n",
    "vocab_size = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_indices(vec):\n",
    "    for idx in vec.nonzero()[0]:\n",
    "        for i in range(int(vec[idx])):\n",
    "            yield idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize\n",
    "# number of times document m and topic z co-occur\n",
    "nmz = np.zeros((n_docs, n_topics))\n",
    "# number of times topic z and word w co-occur\n",
    "nzw = np.zeros((n_topics, vocab_size))\n",
    "nm = np.zeros(n_docs)\n",
    "nz = np.zeros(n_topics)\n",
    "topics = {}\n",
    "for m in range(n_docs):\n",
    "    # i is a number between 0 and doc_length-1\n",
    "    # w is a number between 0 and vocab_size-1\n",
    "    for i, w in enumerate(word_indices(matrix[m, :])):\n",
    "        # choose an arbitrary topic as first topic for word i\n",
    "        z = np.random.randint(n_topics)\n",
    "        nmz[m,z] += 1\n",
    "        nm[m] += 1\n",
    "        nzw[z,w] += 1\n",
    "        nz[z] += 1\n",
    "        topics[(m,i)] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctopic = np.zeros(n_docs);\n",
    "topic_ratio = []\n",
    "for m in range(n_docs):\n",
    "    topicss = []\n",
    "    for i, w in enumerate(word_indices(matrix[m, :])):\n",
    "        topicss.append(topics[(m,i)])\n",
    "    doctopic[m] = max(set(topicss), key=topicss.count)\n",
    "    topic_ratio.append(topicss.count(doctopic[m]) / len(topicss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 14 Titles\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"31 BRAZIL: Nobel Prize winner sides with Brazil's landless. BRASILIA 1996-09-10\",\n",
       " '61 CANADA: Former Quebec premier fought for Canadian unity. QUEBEC CITY 1996-10-02',\n",
       " '64 GERMANY: Vargas Llosa urges sanctions on rights abuses. FRANKFURT 1996-10-06',\n",
       " '79 INDONESIA: Nobel peace awards put East Timor in spotlight. JAKARTA 1996-10-11',\n",
       " '80 NORWAY: Nobel peace award wins praise outside indonesia. OSLO 1996-10-11',\n",
       " \"81 VATICAN: Bishop's Nobel prize sweet satisfaction for Pope. VATICAN CITY 1996-10-11\",\n",
       " '82 NORWAY: Winners of Nobel Peace Prize since 1970. OSLO 1996-10-11',\n",
       " '86 INDONESIA: Nobel laureate invited to gathering for Suharto. JAKARTA 1996-10-14',\n",
       " '126 INDONESIA: Norway issues Timorese Nobel laureate a visa. JAKARTA 1996-11-17',\n",
       " '145 ITALY: Nobel laureate Belo says peace will be his message. ROME 1996-12-06',\n",
       " '151 NORWAY: East Timor activist shares peace prize. OSLO 1996-12-10',\n",
       " \"196 LIBERIA: Liberia's Taylor remarries, offers toast for peace. GBANGA, Liberia 1997-01-28\",\n",
       " \"278 INDONESIA: Seventeen detained after riot on Indonesia's Java. JAKARTA 1997-03-27\",\n",
       " \"306 GERMANY: Germany's Herzog urges Europeans to back unity. AACHEN, Germany 1997-05-08\",\n",
       " \"380 CROATIA: Croatia's Tudjman sworn in for second 5-year term. ZAGREB 1997-08-05\"]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic = 14\n",
    "idx = np.where(doctopic == topic)\n",
    "#titles[idx]\n",
    "idx = idx[0]\n",
    "a = list(titles)\n",
    "k = [a[i] for i in idx]\n",
    "print('Topic', topic, 'Titles')\n",
    "k[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is to display most frequent words in topics\n",
    "topic_word_count = np.zeros((n_topics,vocab_size))\n",
    "for m in range(n_docs):\n",
    "    for i, w in enumerate(word_indices(matrix[m, :])):\n",
    "        topic_word_count[topics[(m,i)], w] = topic_word_count[topics[(m,i)], w] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 = ['elvis', 'music', 'first', 'fans', 'concert', 'film', 'years', 'tour']\n",
      "Topic 1 = ['charles', 'prince', 'diana', 'king', 'royal', 'queen', 'bowles', 'parker']\n",
      "Topic 2 = ['television', 'told', 'says', 'show', 'people', 'group', 'year', \"n't\"]\n",
      "Topic 3 = ['buddhist', 'vietnam', 'law', 'church', 'dent', 'friday', 'temple', 'told']\n",
      "Topic 4 = ['bernardin', 'cardinal', 'church', 'catholic', 'cancer', 'death', 'life', 'chicago']\n",
      "Topic 5 = ['mother', 'teresa', 'order', 'heart', 'charity', 'nuns', 'calcutta', 'sister']\n",
      "Topic 6 = ['church', 'wright', 'million', 'kennedy', 'sale', 'former', 'bishop', 'letters']\n",
      "Topic 7 = ['germany', 'film', 'german', 'nazi', 'letter', 'people', 'scientology', 'against']\n",
      "Topic 8 = ['city', 'west', 'salonika', 'cultural', 'irish', 'israel', 'byzantine', 'israeli']\n",
      "Topic 9 = ['pocahontas', 'bun', 'yet', 'cuba', 'done', 'refused', 'course', 'black']\n",
      "Topic 10 = ['harriman', 'u.s', 'clinton', 'churchill', 'president', 'paris', 'ambassador', 'france']\n",
      "Topic 11 = ['yeltsin', 'president', 'kremlin', 'operation', 'russian', 'heart', 'russia', 'political']\n",
      "Topic 12 = ['spent', 'return', 'local', 'staff', '1995', 'matthew', 'personal', 'birthday']\n",
      "Topic 13 = ['city', 'museum', 'art', 'million', 'century', 'first', 'church', 'people']\n",
      "Topic 14 = ['east', 'peace', 'prize', 'timor', 'belo', 'rights', 'indonesia', 'nobel']\n",
      "Topic 15 = ['simpson', 'york', 'los', 'wallace', 'civil', 'made', 'former', 'public']\n",
      "Topic 16 = ['church', 'romania', 'michael', 'russian', 'russia', 'king', 'family', 'orthodox']\n",
      "Topic 17 = ['minister', 'political', 'leader', 'party', 'former', 'government', 'president', 'prime']\n",
      "Topic 18 = ['pope', 'vatican', 'church', 'john', 'surgery', 'paul', 'world', 'mass']\n",
      "Topic 19 = ['against', 'french', 'bardot', 'france', 'animal', 'moslem', 'later', 'rights']\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_topics):\n",
    "    wordsintopic = topic_word_count[i,:]\n",
    "    mostindices = (-wordsintopic).argsort()[:8]\n",
    "    voclist = list(vocabulary)\n",
    "    mostvocs = [voclist[k] for k in mostindices.tolist()]\n",
    "    print('Topic',i,'=',mostvocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "1960\n",
      "1970\n",
      "1980\n",
      "1990\n"
     ]
    }
   ],
   "source": [
    "#Gibbs steps\n",
    "maxiter = 2000\n",
    "for it in range(maxiter):\n",
    "    if it%10==0:\n",
    "        print(it)\n",
    "    for m in range(n_docs):\n",
    "        for i, w in enumerate(word_indices(matrix[m, :])):\n",
    "            z = topics[(m,i)]\n",
    "            nmz[m,z] -= 1\n",
    "            nm[m] -= 1\n",
    "            nzw[z,w] -= 1\n",
    "            nz[z] -= 1\n",
    "            left = (nzw[:,w] + beta) / (nz + beta * vocab_size)\n",
    "            right = (nmz[m,:] + alpha) / (nm[m] + alpha * n_topics)\n",
    "            p_z = left * right\n",
    "            # normalize to obtain probabilities\n",
    "            p_z /= np.sum(p_z)\n",
    "            z = np.random.multinomial(1,p_z).argmax()\n",
    "\n",
    "            nmz[m,z] += 1\n",
    "            nm[m] += 1\n",
    "            nzw[z,w] += 1\n",
    "            nz[z] += 1\n",
    "            topics[(m,i)] = z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters\n",
    " \n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import reuters \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "def tokenize(text):\n",
    "    min_length = 3\n",
    "    words = map(lambda word: word.lower(), word_tokenize(text));\n",
    "    words = [word for word in words if word not in cachedStopWords]\n",
    "    tokens =(list(map(lambda token: PorterStemmer().stem(token), words)));\n",
    "    p = re.compile('[a-zA-Z]+');\n",
    "    filtered_tokens = list(filter(lambda token: p.match(token) and len(token)>=min_length, tokens));\n",
    "    return filtered_tokens\n",
    "\n",
    "# Return the representer, without transforming\n",
    "def tf_idf(docs):\t\n",
    "    tfidf = TfidfVectorizer(tokenizer=tokenize, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True);\n",
    "    tfidf.fit(docs);\n",
    "    return tfidf;\n",
    "\n",
    "def feature_values(doc, representer):\n",
    "    doc_representation = representer.transform([doc])\n",
    "    features = representer.get_feature_names()\n",
    "    return [(features[index], doc_representation[0, index]) for index in doc_representation.nonzero()[1]]\n",
    "\n",
    "def collection_stats():\n",
    "    # List of documents\n",
    "    documents = reuters.fileids()\n",
    "    print(str(len(documents)) + \" documents\");\n",
    "    \n",
    "    train_docs = list(filter(lambda doc: doc.startswith(\"train\"), documents));\n",
    "    print(str(len(train_docs)) + \" total train documents\");\n",
    "    \n",
    "    test_docs = list(filter(lambda doc: doc.startswith(\"test\"), documents));\t\n",
    "    print(str(len(test_docs)) + \" total test documents\");\n",
    "\n",
    "    # List of categories \n",
    "    categories = reuters.categories();\n",
    "    print(str(len(categories)) + \" categories\");\n",
    "\n",
    "    # Documents in a category\n",
    "    category_docs = reuters.fileids(\"acq\");\n",
    "\n",
    "    # Words for a document\n",
    "    document_id = category_docs[0]\n",
    "    document_words = reuters.words(category_docs[0]);\n",
    "    print(document_words);\n",
    "\n",
    "    # Raw document\n",
    "    print(reuters.raw(document_id));\n",
    "\n",
    "def main():\n",
    "    train_docs = []\n",
    "    test_docs  = []\n",
    "\n",
    "    for doc_id in reuters.fileids():\n",
    "        if doc_id.startswith(\"train\"):\n",
    "            train_docs.append(reuters.raw(doc_id))\n",
    "        else:\n",
    "            test_docs.append(reuters.raw(doc_id))\n",
    "        \n",
    "    representer = tf_idf(train_docs);\n",
    "\n",
    "    for doc in test_docs:\n",
    "        print(feature_values(doc, representer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1854,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 4258)"
      ]
     },
     "execution_count": 1854,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lda\n",
    "import lda.datasets\n",
    "\n",
    "X = lda.datasets.load_reuters()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2036,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "Wi           = []\n",
    "documents    = []\n",
    "train_doc_id = []\n",
    "doc_indice   = 0\n",
    "totallen     = len(reuters.fileids())\n",
    "desired_categ= [1,3,6,10,19]\n",
    "myfileid    = []\n",
    "myfilecateg = []\n",
    "doc_names    = []\n",
    "for i in desired_categ:\n",
    "    for docid in reuters.fileids(reuters.categories()[i]):\n",
    "        if docid.startswith(\"train\"):\n",
    "            myfileid.append(docid)\n",
    "            myfilecateg.append(reuters.categories()[i])\n",
    "myfileids = set(myfileid)\n",
    "\n",
    "new_categs = []\n",
    "for doc_id in myfileids:\n",
    "    if doc_id.startswith(\"train\"):\n",
    "        tokenized_doc = tokenize(reuters.raw(doc_id))\n",
    "        if len(tokenized_doc)>0:\n",
    "            new_categs.append(myfilecateg[myfileid.index(doc_id)])\n",
    "            train_doc_id.append(doc_id)\n",
    "            doc_indice = doc_indice + 1\n",
    "            Wi = Wi + tokenized_doc\n",
    "            doclist = len(tokenized_doc)*[doc_indice]\n",
    "            documents = documents + doclist\n",
    "            doc_names = doc_names + len(tokenized_doc)*[doc_id]\n",
    "        \n",
    "d = {'corpus_words':Wi,'corpus_documents':documents,'doc_ids':doc_names}\n",
    "corpus_df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1968,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alum\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "print(reuters.categories()[i])\n",
    "#reuters.fileids(reuters.categories()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1876,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reuters.raw('training/8933',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2037,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dirichlet priors\n",
    "alpha      = 1\n",
    "beta       = 1\n",
    "vocabulary = set(Wi)\n",
    "vocabulary = list(vocabulary)\n",
    "\n",
    "#set the numbers\n",
    "n_docs = doc_indice\n",
    "n_topics = 5\n",
    "vocab_size = len(vocabulary)\n",
    "\n",
    "#get matrix\n",
    "matrix = np.zeros((n_docs, vocab_size))\n",
    "doc_list = []\n",
    "for m in range(n_docs):\n",
    "    doc_list.append([train_doc_id[m]] * corpus_df.corpus_documents.value_counts()[m+1])\n",
    "    df_doc = corpus_df.loc[corpus_df['corpus_documents'] == (m+1)]\n",
    "    doc_unique_words = df_doc.corpus_words.unique()\n",
    "    for docword in doc_unique_words:\n",
    "        n = vocabulary.index(docword)\n",
    "        matrix[m,n] = df_doc.corpus_words.value_counts()[docword]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1973,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_indices(vec):\n",
    "    for idx in vec.nonzero()[0]:\n",
    "        for i in range(int(vec[idx])):\n",
    "            yield idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2038,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize\n",
    "# number of times document m and topic z co-occur\n",
    "nmz = np.zeros((n_docs, n_topics))\n",
    "# number of times topic z and word w co-occur\n",
    "nzw = np.zeros((n_topics, vocab_size))\n",
    "nm = np.zeros(n_docs)\n",
    "nz = np.zeros(n_topics)\n",
    "topics = {}\n",
    "for m in range(n_docs):\n",
    "    # i is a number between 0 and doc_length-1\n",
    "    # w is a number between 0 and vocab_size-1\n",
    "    for i, w in enumerate(word_indices(matrix[m, :])):\n",
    "        # choose an arbitrary topic as first topic for word i\n",
    "        z = np.random.randint(n_topics)\n",
    "        nmz[m,z] += 1\n",
    "        nm[m] += 1\n",
    "        nzw[z,w] += 1\n",
    "        nz[z] += 1\n",
    "        topics[(m,i)] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2005,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cocoa'"
      ]
     },
     "execution_count": 2005,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a[\"doc_labels\"].values.tolist()\n",
    "a = np.unique(compare_df[\"doc_labels\"].values)\n",
    "a.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2035,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 2035,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = compare_df.loc[compare_df['doc_labels'] == 'dlr']\n",
    "len(a[\"doc_lda\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2041,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reuters_bop</th>\n",
       "      <th>lda_bop</th>\n",
       "      <th>reuters_cocoa</th>\n",
       "      <th>lda_cocoa</th>\n",
       "      <th>reuters_copper</th>\n",
       "      <th>lda_copper</th>\n",
       "      <th>reuters_dlr</th>\n",
       "      <th>lda_dlr</th>\n",
       "      <th>reuters_alum</th>\n",
       "      <th>lda_alum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bop</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>copper</td>\n",
       "      <td>3.0</td>\n",
       "      <td>dlr</td>\n",
       "      <td>2.0</td>\n",
       "      <td>alum</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bop</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>copper</td>\n",
       "      <td>3.0</td>\n",
       "      <td>dlr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alum</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bop</td>\n",
       "      <td>2.0</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>copper</td>\n",
       "      <td>3.0</td>\n",
       "      <td>dlr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alum</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bop</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>copper</td>\n",
       "      <td>3.0</td>\n",
       "      <td>dlr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alum</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bop</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>copper</td>\n",
       "      <td>3.0</td>\n",
       "      <td>dlr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alum</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bop</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>copper</td>\n",
       "      <td>3.0</td>\n",
       "      <td>dlr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alum</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bop</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>copper</td>\n",
       "      <td>3.0</td>\n",
       "      <td>dlr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alum</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bop</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>copper</td>\n",
       "      <td>3.0</td>\n",
       "      <td>dlr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alum</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bop</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>copper</td>\n",
       "      <td>3.0</td>\n",
       "      <td>dlr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alum</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bop</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>2.0</td>\n",
       "      <td>copper</td>\n",
       "      <td>3.0</td>\n",
       "      <td>dlr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alum</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bop</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>copper</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dlr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alum</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bop</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>copper</td>\n",
       "      <td>3.0</td>\n",
       "      <td>dlr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alum</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bop</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>copper</td>\n",
       "      <td>2.0</td>\n",
       "      <td>dlr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alum</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bop</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>copper</td>\n",
       "      <td>3.0</td>\n",
       "      <td>dlr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alum</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bop</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>copper</td>\n",
       "      <td>3.0</td>\n",
       "      <td>dlr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alum</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reuters_bop  lda_bop reuters_cocoa  lda_cocoa reuters_copper  lda_copper  \\\n",
       "0          bop      1.0         cocoa        4.0         copper         3.0   \n",
       "1          bop      1.0         cocoa        4.0         copper         3.0   \n",
       "2          bop      2.0         cocoa        4.0         copper         3.0   \n",
       "3          bop      1.0         cocoa        4.0         copper         3.0   \n",
       "4          bop      1.0         cocoa        4.0         copper         3.0   \n",
       "5          bop      1.0         cocoa        4.0         copper         3.0   \n",
       "6          bop      1.0         cocoa        4.0         copper         3.0   \n",
       "7          bop      1.0         cocoa        4.0         copper         3.0   \n",
       "8          bop      1.0         cocoa        4.0         copper         3.0   \n",
       "9          bop      1.0         cocoa        2.0         copper         3.0   \n",
       "10         bop      1.0         cocoa        4.0         copper         0.0   \n",
       "11         bop      1.0         cocoa        4.0         copper         3.0   \n",
       "12         bop      1.0         cocoa        1.0         copper         2.0   \n",
       "13         bop      1.0         cocoa        4.0         copper         3.0   \n",
       "14         bop      1.0         cocoa        4.0         copper         3.0   \n",
       "\n",
       "   reuters_dlr  lda_dlr reuters_alum  lda_alum  \n",
       "0          dlr      2.0         alum       3.0  \n",
       "1          dlr      0.0         alum       1.0  \n",
       "2          dlr      0.0         alum       3.0  \n",
       "3          dlr      0.0         alum       3.0  \n",
       "4          dlr      0.0         alum       3.0  \n",
       "5          dlr      0.0         alum       3.0  \n",
       "6          dlr      0.0         alum       3.0  \n",
       "7          dlr      0.0         alum       3.0  \n",
       "8          dlr      0.0         alum       3.0  \n",
       "9          dlr      0.0         alum       3.0  \n",
       "10         dlr      0.0         alum       3.0  \n",
       "11         dlr      0.0         alum       3.0  \n",
       "12         dlr      0.0         alum       3.0  \n",
       "13         dlr      0.0         alum       3.0  \n",
       "14         dlr      0.0         alum       3.0  "
      ]
     },
     "execution_count": 2041,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = {'doc_labels':new_categs,'doc_lda':doctopic}\n",
    "compare_df = pd.DataFrame(k)\n",
    "a = compare_df.loc[compare_df['doc_labels'] == 'bop']\n",
    "a1_lab = a[\"doc_labels\"].values[:15].tolist()\n",
    "a1_top = a[\"doc_lda\"].values[:15].tolist()\n",
    "a = compare_df.loc[compare_df['doc_labels'] == 'cocoa']\n",
    "a2_lab = a[\"doc_labels\"].values[:15].tolist()\n",
    "a2_top = a[\"doc_lda\"].values[:15].tolist()\n",
    "a = compare_df.loc[compare_df['doc_labels'] == 'copper']\n",
    "a3_lab = a[\"doc_labels\"].values[:15].tolist()\n",
    "a3_top = a[\"doc_lda\"].values[:15].tolist()\n",
    "a = compare_df.loc[compare_df['doc_labels'] == 'dlr']\n",
    "a4_lab = a[\"doc_labels\"].values[:15].tolist()\n",
    "a4_top = a[\"doc_lda\"].values[:15].tolist()\n",
    "a = compare_df.loc[compare_df['doc_labels'] == 'alum']\n",
    "a5_lab = a[\"doc_labels\"].values[:15].tolist()\n",
    "a5_top = a[\"doc_lda\"].values[:15].tolist()\n",
    "k = {'reuters_bop':a1_lab,'lda_bop':a1_top,'reuters_cocoa':a2_lab,'lda_cocoa':a2_top,'reuters_copper':a3_lab,'lda_copper':a3_top,'reuters_dlr':a4_lab,'lda_dlr':a4_top,'reuters_alum':a5_lab,'lda_alum':a5_top}\n",
    "dff = pd.DataFrame(k)\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2039,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2039-34b5b8e46310>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mnzw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mnz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnzw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnz\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnmz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mp_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Gibbs steps\n",
    "maxiter = 2000\n",
    "for it in range(maxiter):\n",
    "    if it%10==0:\n",
    "        print(it)\n",
    "    for m in range(n_docs):\n",
    "        for i, w in enumerate(word_indices(matrix[m, :])):\n",
    "            z = topics[(m,i)]\n",
    "            nmz[m,z] -= 1\n",
    "            nm[m] -= 1\n",
    "            nzw[z,w] -= 1\n",
    "            nz[z] -= 1\n",
    "            left = (nzw[:,w] + beta) / (nz + beta * vocab_size)\n",
    "            right = (nmz[m,:] + alpha) / (nm[m] + alpha * n_topics)\n",
    "            p_z = left * right\n",
    "            # normalize to obtain probabilities\n",
    "            p_z /= np.sum(p_z)\n",
    "            z = np.random.multinomial(1,p_z).argmax()\n",
    "\n",
    "            nmz[m,z] += 1\n",
    "            nm[m] += 1\n",
    "            nzw[z,w] += 1\n",
    "            nz[z] += 1\n",
    "            topics[(m,i)] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2040,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctopic = np.zeros(n_docs);\n",
    "topic_ratio = []\n",
    "for m in range(n_docs):\n",
    "    topicss = []\n",
    "    for i, w in enumerate(word_indices(matrix[m, :])):\n",
    "        topicss.append(topics[(m,i)])\n",
    "    doctopic[m] = max(set(topicss), key=topicss.count)\n",
    "    topic_ratio.append(topicss.count(doctopic[m]) / len(topicss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
